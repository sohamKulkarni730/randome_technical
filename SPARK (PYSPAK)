      1.SPARK 3 preview on Linux(ubuntu 18)
            wget https://mirrors.estointernet.in/apache/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz
            cd /usr
            mkdir /spark_home
            cd /home/soham/downloads  OR cd ~/downloads
            tar -xvf sspark-3.1.1-bin-hadoop2.7.tgz -C /usr/spark_home
            
            #this might not needed , but if needed run manually and check if this has worked
            #sudo mv /usr/spark_home/sspark-3.1.1-bin-hadoop2.7/{.,}* /usr/spark_home
            
            #sudo rmdir (to remove directory)

            JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64
            PATH=$JAVA_HOME/bin:$PATH
            export JAVA_HOME
            export PATH
            #The most important  step to esure pyspark runs
            export PYSPARK_PYTHON=python3

            SPARK_HOME=/usr/spark_home
            PATH=$SPARK_HOME/bin:$PATH
            export SPARK_HOME
            export PATH
            
            sudo apt install python3-pip
            pip3 --version
            pip install notebook
            
            
            
            
      2. Creating spark scheam in DLL string and in structType in (Python and Java)
      
      3. Coelese is used for performance reasons,Coelese divides an RDD into number of partition of outr choice. if we choose partiion to be one tit will perform like collect()
            . But unlike collect() result will still be an RDD. we can change the number of partitions and hence no of spark node working at a time
      
      4. data skew is a huge problem in big data applications, exmple is when we do a groupBy operations , we eend up having n numberof groups of data 
            and that might occupy only n number of worker instaed of all of the workers in cluster. This makes work distribution uneven and results in 
            time lag / performance degradation (But how do we get to know about data distribution befor grouping them ? If we can tge this data before grouping then,
            we have to group them by key and then perform following transformations on that perticular large group ). 
            A way to deal withthis called salting. Salting makes key change into aratificial keys , ie.e ram is replaced with 
            ram1 and ram2 . thus in group by opration those two key are treated as different and number of partition increases-> resulting in better utilisation of whole
            cluster.
            but salting should be used a a last tool to deal with skewing problem as more number of partition will increase work in shuffle stage and networ is goinf to be suffer.
            Anywasys , salting need some testing to be done to know whthere benefits of implementing are outways the implemenion efforts
